{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Structured Predictors\n",
    "\n",
    "In this class, we will continue to focus on sequence classification, but instead of following a generative approach (like in the previous chapter) we move towards discriminative approaches. Recall that the difference between these approaches is that generative approaches attempt to model the probability distribution of the data, P(X, Y), whereas discriminative ones only model the conditional probability of the sequence, given the observed data, P(Y|X).\n",
    "\n",
    "In this class, we will continue to focus on sequence classification, but instead of following a generative ap- proach (like in the previous chapter) we move towards discriminative approaches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Exercise 4.1 </b> In this exercise you will train a CRF using different feature sets for Part-of-Speech Tagging. Start with the code below, which uses the ID feature set from table 4.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRF Exercise\n",
      "Epoch: 0 Objective value: -5.779018\n",
      "Epoch: 1 Objective value: -3.192724\n",
      "Epoch: 2 Objective value: -2.717537\n",
      "Epoch: 3 Objective value: -2.436614\n",
      "Epoch: 4 Objective value: -2.240491\n",
      "Epoch: 5 Objective value: -2.091833\n",
      "Epoch: 6 Objective value: -1.973353\n",
      "Epoch: 7 Objective value: -1.875643\n",
      "Epoch: 8 Objective value: -1.793034\n",
      "Epoch: 9 Objective value: -1.721857\n",
      "Epoch: 10 Objective value: -1.659605\n",
      "Epoch: 11 Objective value: -1.604499\n",
      "Epoch: 12 Objective value: -1.555229\n",
      "Epoch: 13 Objective value: -1.510806\n",
      "Epoch: 14 Objective value: -1.470468\n",
      "Epoch: 15 Objective value: -1.433612\n",
      "Epoch: 16 Objective value: -1.399759\n",
      "Epoch: 17 Objective value: -1.368518\n",
      "Epoch: 18 Objective value: -1.339566\n",
      "Epoch: 19 Objective value: -1.312636\n"
     ]
    }
   ],
   "source": [
    "import lxmls.sequences.crf_online as crfo\n",
    "import lxmls.sequences.structured_perceptron as spc\n",
    "import lxmls.readers.pos_corpus as pcc\n",
    "import lxmls.sequences.id_feature as idfc\n",
    "import lxmls.sequences.extended_feature as exfc\n",
    "print \"CRF Exercise\"\n",
    "corpus = pcc.PostagCorpus()\n",
    "train_seq = corpus.read_sequence_list_conll(\"data/train-02-21.conll\",max_sent_len=10,\n",
    "    max_nr_sent=1000)\n",
    "test_seq = corpus.read_sequence_list_conll(\"data/test-23.conll\",max_sent_len=10,\n",
    "    max_nr_sent=1000)\n",
    "dev_seq = corpus.read_sequence_list_conll(\"data/dev-22.conll\",max_sent_len=10,max_nr_sent\n",
    "    =1000)\n",
    "feature_mapper = idfc.IDFeatures(train_seq)\n",
    "feature_mapper.build_features()\n",
    "crf_online = crfo.CRFOnline(corpus.word_dict, corpus.tag_dict, feature_mapper)\n",
    "crf_online.num_epochs = 20\n",
    "crf_online.train_supervised(train_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You will receive feedback when each epoch is finished, note that running the 20 epochs might take a while. After training is done, evaluate the learned model on the training, development and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRF - ID Features Accuracy Train: 0.949 Dev: 0.846 Test: 0.858\n"
     ]
    }
   ],
   "source": [
    "pred_train = crf_online.viterbi_decode_corpus(train_seq)\n",
    "pred_dev = crf_online.viterbi_decode_corpus(dev_seq)\n",
    "pred_test = crf_online.viterbi_decode_corpus(test_seq)\n",
    "eval_train = crf_online.evaluate_corpus(train_seq, pred_train)\n",
    "eval_dev = crf_online.evaluate_corpus(dev_seq, pred_dev)\n",
    "eval_test = crf_online.evaluate_corpus(test_seq, pred_test)\n",
    "print \"CRF - ID Features Accuracy Train: %.3f Dev: %.3f Test: %.3f\"%(eval_train,eval_dev, eval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Even using a similar feature set a CRF yields better results than the HMM from the previous lecture. Perform some error analysis and figure out what are the main errors the tagger is making. Compare them with the errors made by the HMM model. (Hint: use the methods developed in the previous lecture to help you with the error analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11444b9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lxmls.sequences.confusion_matrix as cm\n",
    "import matplotlib.pyplot as plt\n",
    "confusion_matrix = cm.build_confusion_matrix(test_seq.seq_list, pred_test, len(\n",
    "corpus.tag_dict), crf_online.get_num_states())\n",
    "cm.plot_confusion_bar_graph(confusion_matrix, corpus.tag_dict, xrange(crf_online.get_num_states\n",
    "    ()), 'Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Exercise 4.2 </b> \n",
    "\n",
    "Repeat the previous exercise using the extended feature set. Compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Objective value: -7.141596\n",
      "Epoch: 1 Objective value: -1.807511\n",
      "Epoch: 2 Objective value: -1.218877\n",
      "Epoch: 3 Objective value: -0.955739\n",
      "Epoch: 4 Objective value: -0.807821\n",
      "Epoch: 5 Objective value: -0.712858\n",
      "Epoch: 6 Objective value: -0.647382\n",
      "Epoch: 7 Objective value: -0.599442\n",
      "Epoch: 8 Objective value: -0.562584\n",
      "Epoch: 9 Objective value: -0.533411\n",
      "Epoch: 10 Objective value: -0.509885\n",
      "Epoch: 11 Objective value: -0.490548\n",
      "Epoch: 12 Objective value: -0.474318\n",
      "Epoch: 13 Objective value: -0.460438\n",
      "Epoch: 14 Objective value: -0.448389\n",
      "Epoch: 15 Objective value: -0.437800\n",
      "Epoch: 16 Objective value: -0.428402\n",
      "Epoch: 17 Objective value: -0.419990\n",
      "Epoch: 18 Objective value: -0.412406\n",
      "Epoch: 19 Objective value: -0.405524\n"
     ]
    }
   ],
   "source": [
    "feature_mapper = exfc.ExtendedFeatures(train_seq)\n",
    "feature_mapper.build_features()\n",
    "crf_online = crfo.CRFOnline(corpus.word_dict, corpus.tag_dict, feature_mapper)\n",
    "crf_online.num_epochs = 20\n",
    "crf_online.train_supervised(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRF - Extended Features Accuracy Train: 0.984 Dev: 0.899 Test: 0.894\n"
     ]
    }
   ],
   "source": [
    "pred_train = crf_online.viterbi_decode_corpus(train_seq)\n",
    "pred_dev = crf_online.viterbi_decode_corpus(dev_seq)\n",
    "pred_test = crf_online.viterbi_decode_corpus(test_seq)\n",
    "eval_train = crf_online.evaluate_corpus(train_seq, pred_train)\n",
    "eval_dev = crf_online.evaluate_corpus(dev_seq, pred_dev)\n",
    "eval_test = crf_online.evaluate_corpus(test_seq, pred_test)\n",
    "print \"CRF - Extended Features Accuracy Train: %.3f Dev: %.3f Test: %.3f\"%(eval_train, eval_dev,eval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Compare the errors obtained with the two different feature sets. Do some error analysis: what errors were correct by using more features? Can you think of other features to use to solve the errors found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d86e790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lxmls.sequences.confusion_matrix as cm\n",
    "import matplotlib.pyplot as plt\n",
    "confusion_matrix = cm.build_confusion_matrix(test_seq.seq_list, pred_test, len(\n",
    "corpus.tag_dict), crf_online.get_num_states())\n",
    "cm.plot_confusion_bar_graph(confusion_matrix, corpus.tag_dict, xrange(crf_online.get_num_states\n",
    "    ()), 'Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Compare the errors obtained with the two different feature sets. Do some error analysis: what errors were correct by using more features? Can you think of other features to use to solve the errors found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using more features, such as the uppercase feature, the tagger is now making less errors in terms of nouns, verbs, ,adjectives and so on. Some other features that could be considered: words that end with ly (>adverbs), or that end with ed (>verb); or that end with ful (> adjective); and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Perceptron\n",
    "\n",
    "<b> Exercise 4.3 </b> \n",
    "\n",
    "Implement the structured perceptron algorithm. To do this, edit file sequences/structured perceptron.py and implement the function <i> def perceptron_update(self, sequence)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_update(self, sequence):\n",
    "\n",
    "    # ----------\n",
    "    # Solution to Exercise 4.3\n",
    "\n",
    "    predicted_sequence, total_score = self.viterbi_decode(sequence)\n",
    "    y_hat=predicted_sequence.y\n",
    "    y_true=sequence.y\n",
    "\n",
    "    num_labels=0\n",
    "    num_mistakes=0\n",
    "\n",
    "    #init\n",
    "    y_true_init=y_true[0]\n",
    "    y_hat_init= y_hat[0]\n",
    "\n",
    "    if y_true_init != y_hat_init:\n",
    "\n",
    "        self.parameters[self.feature_mapper.get_initial_features(sequence, y_true_init)] += self.learning_rate\n",
    "\n",
    "        self.parameters[self.feature_mapper.get_initial_features(sequence, y_hat_init)] -= self.learning_rate\n",
    "\n",
    "\n",
    "    length=len(y_true)\n",
    "\n",
    "    for t in xrange(length):\n",
    "\n",
    "         #emissions\n",
    "        y_true_t = y_true[t]\n",
    "        y_hat_t  = y_hat[t]\n",
    "\n",
    "        num_labels += 1\n",
    "        if y_true_t != y_hat_t:\n",
    "            num_mistakes += 1\n",
    "\n",
    "\n",
    "            self.parameters[self.feature_mapper.get_emission_features(sequence, t, y_true_t)] += self.learning_rate\n",
    "            self.parameters[self.feature_mapper.get_emission_features(sequence, t, y_hat_t)] -= self.learning_rate\n",
    "\n",
    "        if t > 0:\n",
    "            # transitions\n",
    "            prev_y_true_t = y_true[t-1]\n",
    "            prev_y_hat_y = y_hat[t-1]\n",
    "\n",
    "            if y_true_t != y_hat_t or prev_y_true_t != prev_y_hat_y:\n",
    "\n",
    "                self.parameters[self.feature_mapper.get_transition_features(\n",
    "                    sequence, t-1, y_true_t, prev_y_true_t)] += self.learning_rate\n",
    "\n",
    "                self.parameters[self.feature_mapper.get_transition_features(\n",
    "                    sequence, t-1, y_hat_t, prev_y_hat_y)] -= self.learning_rate\n",
    "\n",
    "\n",
    "    #final\n",
    "    y_true_final = y_true[length-1]\n",
    "    y_hat_final = y_hat[length-1]\n",
    "\n",
    "    if y_true_final != y_hat_final:\n",
    "        self.parameters[self.feature_mapper.get_final_features(sequence, y_true_final)] += self.learning_rate\n",
    "\n",
    "        self.parameters[self.feature_mapper.get_final_features(sequence, y_hat_final)] -= self.learning_rate\n",
    "\n",
    "    return num_labels, num_mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Exercise 4.4 </b>\n",
    "\n",
    "Repeat Exercises 4.1â€“4.2 using the structured perceptron algorithm instead of a CRF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Simple feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Exercise\n",
      "Epoch: 0 Accuracy: 0.656806\n",
      "Epoch: 1 Accuracy: 0.820898\n",
      "Epoch: 2 Accuracy: 0.879176\n",
      "Epoch: 3 Accuracy: 0.907432\n",
      "Epoch: 4 Accuracy: 0.925239\n",
      "Epoch: 5 Accuracy: 0.939956\n",
      "Epoch: 6 Accuracy: 0.946284\n",
      "Epoch: 7 Accuracy: 0.953790\n",
      "Epoch: 8 Accuracy: 0.958499\n",
      "Epoch: 9 Accuracy: 0.955114\n",
      "Epoch: 10 Accuracy: 0.959235\n",
      "Epoch: 11 Accuracy: 0.968065\n",
      "Epoch: 12 Accuracy: 0.968212\n",
      "Epoch: 13 Accuracy: 0.966740\n",
      "Epoch: 14 Accuracy: 0.971302\n",
      "Epoch: 15 Accuracy: 0.968653\n",
      "Epoch: 16 Accuracy: 0.970419\n",
      "Epoch: 17 Accuracy: 0.971891\n",
      "Epoch: 18 Accuracy: 0.971744\n",
      "Epoch: 19 Accuracy: 0.973510\n"
     ]
    }
   ],
   "source": [
    "feature_mapper = idfc.IDFeatures(train_seq)\n",
    "feature_mapper.build_features()\n",
    "print \"Perceptron Exercise\"\n",
    "sp = spc.StructuredPerceptron(corpus.word_dict, corpus.tag_dict, feature_mapper)\n",
    "sp.num_epochs = 20\n",
    "sp.train_supervised(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Perceptron - ID Features Accuracy Train: 0.984 Dev: 0.835 Test: 0.840\n"
     ]
    }
   ],
   "source": [
    "pred_train = sp.viterbi_decode_corpus(train_seq)\n",
    "pred_dev = sp.viterbi_decode_corpus(dev_seq)\n",
    "pred_test = sp.viterbi_decode_corpus(test_seq)\n",
    "eval_train = sp.evaluate_corpus(train_seq, pred_train)\n",
    "eval_dev = sp.evaluate_corpus(dev_seq, pred_dev)\n",
    "eval_test = sp.evaluate_corpus(test_seq, pred_test)\n",
    "print \"Structured Perceptron - ID Features Accuracy Train: %.3f Dev: %.3f Test: %.3f\"%( eval_train,eval_dev,eval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Extended feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.764386\n",
      "Epoch: 1 Accuracy: 0.872701\n",
      "Epoch: 2 Accuracy: 0.903458\n",
      "Epoch: 3 Accuracy: 0.927594\n",
      "Epoch: 4 Accuracy: 0.938484\n",
      "Epoch: 5 Accuracy: 0.951141\n",
      "Epoch: 6 Accuracy: 0.949816\n",
      "Epoch: 7 Accuracy: 0.959529\n",
      "Epoch: 8 Accuracy: 0.957616\n",
      "Epoch: 9 Accuracy: 0.962325\n",
      "Epoch: 10 Accuracy: 0.961148\n",
      "Epoch: 11 Accuracy: 0.970567\n",
      "Epoch: 12 Accuracy: 0.968212\n",
      "Epoch: 13 Accuracy: 0.973216\n",
      "Epoch: 14 Accuracy: 0.974393\n",
      "Epoch: 15 Accuracy: 0.973951\n",
      "Epoch: 16 Accuracy: 0.976600\n",
      "Epoch: 17 Accuracy: 0.977483\n",
      "Epoch: 18 Accuracy: 0.974834\n",
      "Epoch: 19 Accuracy: 0.977042\n"
     ]
    }
   ],
   "source": [
    "feature_mapper = exfc.ExtendedFeatures(train_seq)\n",
    "feature_mapper.build_features()\n",
    "sp = spc.StructuredPerceptron(corpus.word_dict, corpus.tag_dict, feature_mapper)\n",
    "sp.num_epochs = 20\n",
    "sp.train_supervised(train_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Perceptron - Extended Features Accuracy Train: 0.984 Dev: 0.888 Test: 0.890\n"
     ]
    }
   ],
   "source": [
    "pred_train = sp.viterbi_decode_corpus(train_seq)\n",
    "pred_dev = sp.viterbi_decode_corpus(dev_seq)\n",
    "pred_test = sp.viterbi_decode_corpus(test_seq)\n",
    "eval_train = sp.evaluate_corpus(train_seq, pred_train)\n",
    "eval_dev = sp.evaluate_corpus(dev_seq, pred_dev)\n",
    "eval_test = sp.evaluate_corpus(test_seq, pred_test)\n",
    "print \"Structured Perceptron - Extended Features Accuracy Train: %.3f Dev: %.3f Test: %.3f\"%( eval_train,eval_dev,eval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Report the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could observe with the results, Structured Perceptron is much faster than CRF, being just slighlty worse at the test set. This very simple algorithm achieved great results, being not only easy to implement, but also a lot faster than CRF, which makes him a good first choice to try. \n",
    "\n",
    "CRF - ID Features Accuracy Train: 0.949 Dev: 0.846 Test: 0.858\n",
    "\n",
    "Structured Perceptron - ID Features Accuracy Train: 0.984 Dev: 0.835 Test: 0.840\n",
    "\n",
    "CRF - Extended Features Accuracy Train: 0.984 Dev: 0.899 Test: 0.894\n",
    "            \n",
    "Structured Perceptron - Extended Features Accuracy Train: 0.984 Dev: 0.888 Test: 0.890\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
